{"cells": [{"metadata": {}, "cell_type": "markdown", "source": ["# Using R to analyze racial disparities in SF traffic stops\n", "\n", "To start getting our hands dirty with applying our `R` skills, we're going to explore San Francisco's traffic stops. Our goals today are twofold:\n", "1. To learn how to use `R` to deal with data and to answer policy questions. In addition to data-munging, we'll be computing descriptive statistics, plotting and even doing some modeling!\n", "2. To get in the data science mindset: learning how to answer questions about social policies using data. In our case, we'll investigate whether there is racial discrimination in SF's policing practices, and we'll evaluate the impacts of certain policy changes like the legalization of marijuana.\n", "\n", "## Getting started \n", "\n", "First, let's load the necessary libraries and data that will allow us to begin our investigation!"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Some initial setup\n", "options(digits = 3)\n", "library(tidyverse)\n", "library(lubridate)\n", "theme_set(theme_bw())\n", "getwd()\n", "\n", "# Read the data\n", "stops <- read_rds(\"data/san_francisco_stop_data.rds\")\n", "pop_2015 <- read_rds(\"data/sf_pop_2015.rds\")"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Covering the basics\n", "\n", "The core of `R` is the dataframe. We've given you one to start with, in the form\n", "of `stops`. Think of dataframes like a spreadsheet: they have rows and columns.\n", "Usually, rows are a \"datapoint\": in `stops`, each row corresponds to a single\n", "stop from San Francisco. The columns are the \"variables\": again, in `stops`,\n", "these are the things we know about the stop, like where the stop happened, the\n", "age of the driver, whether an arrest was made, and so on.\n", "\n", "We can take a peak simply by typing `stops` into an R chunk:"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["head(stops)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Functions\n", "\n", "Functions are a way to \"do something\" to an input. So `f(a)=b` takes a number `a`, and applies `f()`, and gets the output `b`. In programming, we also have functions! Most of the functions we'll use allow us to manipulate our dataframe as the input. \n", "\n", "The function `head(stops)` gave us the first 6 rows of our data frame. If we want to find the number of rows in our dataframe, we'd use the function `nrow()`, which takes a dataframe (like `stops`) as an input, and then outputs an integer (the number of rows in `stops`)."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["nrow(stops)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Your turn\n", "\n", "To find the number of columns, we (unsurprisingly) use `ncol`. Try it!"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Find the number of columns in `stops`\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["To figure out what the names of our columns are, we can use `colnames()`."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Find the column names in `stops`\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["**Pro-tip:** If you're ever confused about a function and want to know more about it, what it does, how to use it, etc., every function has \"documentation\" to help! To know more about the `head()` function, simply run a code chunk with `?head`. It provides way more information than you might want or need -- but if you scroll down to the \"Examples\" section, those usually help!"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 1: Stop dates\n", "\n", "For this first exercise, let's get a better sense of what time range our `stops` data covers. To do this, we'll be dealing with the `date` column in our dataframe. \n", "\n", "1. What happens when you run `stops$date`? How about `pull(stops, date)`? What do `$` and `pull()` do?\n", "\n", "2. What date range does our dataset cover? (Hint: Try exploring the `min()` and `max()` functions, or the `range()` function!)"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["## EXERCISE 1: YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Take a look at the two versions of the code below. They do the same thing. See if you can understand what's going on in the second one -- what does `%>%` seem to be doing?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Confirm that these give the same answer:\n", "\n", "# Method 1: nested\n", "range(pull(stops, date))\n", "\n", "# Method 2: multi-line\n", "stops %>% \n", "    pull(date) %>% \n", "    range()\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["**tidyverse tip**: The second method uses a funky symbol, `%>%` called the \"pipe\", which is the crux of the tidyverse. The pipe helps to keep our code clean. It allows us to read top-down rather than inside-out (which is what method 1 above requires of us). Each line simply applies to the result of the previous line:\n", "* We start with `stops`,\n", "* then we apply `pull(date)` to the above (stops), getting us a list of dates,\n", "* then we apply `range()` to the above (a list of dates).\n", "\n", "More formally, the pipe operator\n", "just places the previous item into the first argument of the function. So,\n", "`x %>% f()` is simply `f(x)`. While in a one-function call the pipe might feel\n", "silly and unnecessary, it's going to become _really_ helpful once we start\n", "wanting to do multiple transformations to our data. "]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Preparing our data\n", "\n", "For some of our analysis, we'll want to focus on the most recent full year: 2015.\n", "\n", "To do this we'll want to use the _year_ of each stop, but _year_ isn't currently a column in our dataset. Let's add it!"]}, {"metadata": {}, "cell_type": "markdown", "source": ["**tidyverse function: `mutate()`**\n", "\n", "We can use the `mutate()` function to fix add a `yr` column to `stops`.\n", "The `mutate()` function adds new columns to a dataframe based on old columns.\n", "The basic setup is `mutate(DATA, NEW_COL = FUN(OLD_COL))` where \n", "* `DATA` is our\n", "dataframe, \n", "* `NEW_COL` is the name of the new column we want, and \n", "* `FUN` is the function we apply to the old column, `OLD_COL`, to get it.\n", "\n", "### You try!\n", "\n", "In the space below:\n", "\n", "1. use the `year()` and `mutate()` functions to add a new column called `yr` to our `stops` dataframe, and\n", "2. use the assignment operator `<-` (it's like = in `R`) to create a new variable, `stops_w_yr`."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Add a yr column to `stops`\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["**Note:** When we write code chunks and _don't_ save our result using `<-`, that result does not overwrite or in any way change the data. To change the data, we need to use the process above, creating a new variable, or we could overwrite the original dataframe (`stops <- stops %>% ...` -- but be careful, because you could accidentally overwrite the dataframe with something you didn't expect!)"]}, {"metadata": {}, "cell_type": "markdown", "source": ["Now, we can investigate this new `yr` column in a few ways. \n", "1. We can check it's acutally there by looking at `colnames(stops_w_yr)`.\n", "2. We can compute the range of years using `range(stops_w_yr$yr)`.\n", "3. We can count the number of stops per year: `stops_w_yr %>% count(yr)`. \n", "\n", "### You try\n", "\n", "Play around with these! Make sure to try the last one."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Investigate your new `yr` column. \n", "# Make sure to try counting the number of stops per year!\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Discuss\n", "\n", "What do you notice about stop counts over the years?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### Back to data prep\n", "\n", "Now let's get back to prepping our data. To get to our desired date range of the most recent full year (2015), we will \n", "1. Use the `filter()` function to specify the years we want, and \n", "2. Again use the assignment operator `<-` (it's like = in `R`) to create a new variable, `stops_2015`."]}, {"metadata": {}, "cell_type": "markdown", "source": ["**tidyverse function: `filter()`**\n", "\n", "* The `filter()` function is used to separate rows from the dataframe that\n", "interest us from rows that do not. \n", "* In particular, `filter(DATA, CONDITION)`\n", "returns `DATA` with all of the rows that satisfy `CONDITION` removed. \n", "* For\n", "instance, we might want to only look at stops from 2015. To do this, we would type `stops %>% filter(yr == 2015)`, since we only want\n", "rows from `stops` where the `yr` column is (i.e., `==`) `2015`. \n", "* We can also filter on multiple conditions, just separating each condition with a comma. So, for example, if we wanted all stops between 2011 and 2015, we would write `stops %>% filter(yr >= 2011, yr <=2015)`.\n", "\n", "### Your turn\n", "\n", "Create a new variable, `stops_2015` that is our stops dataframe filtered to just those that happened in the year (`yr`) 2015. "]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Use the filter function to get just stops from 2015\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Just to be extra sure, let's check our date range in this new dataframe, `stops_2015`!"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# What date range does stops_2015 cover?\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Challenge\n", "\n", "Look back and the stop counts by year -- are there any years that look suspicious? How could we use `filter()` and `range()` to investigate whether suspiciously low years have a full year of data?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Try it out!\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Getting multiple answers at once!\n", "\n", "To answer the challenge problem above, we'd have to filter to an individual year of data in order to test the date range of that year. Instead of doing this _for each_ year separately, let's do it all in one go! \n", "\n", "There are two different methods to do this: one involves plotting, and one involves two new `tidyverse` functions. Let's start with plotting\n", "\n", "### Plotting\n", "\n", "The basics of plotting use a package called `ggplot2`. The idea behind this package is that you start with a dataset, and then layer the elements you want: points, lines, bars, tweaking the x-axis, tweaking the title, etc. Each thing you'd want to do is a separate function. The difference between `ggplot` and what we've been doing before, is that the functions for plotting are strung together with `+` rather than with `%>%`.\n", "\n", "We'll walk you through the first plot, and then you'll have ample opportunities to create your own plots throughout the afternoon!"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    count(yr) %>%\n", "    # \"aes()\" stands for \"aesthetic\". \n", "    # Anything within `aes()` refers to information from our data (stops_w_yr)\n", "    ggplot(aes(x = yr, y = n)) + \n", "    # geom_col just creates bar columns using the x and y coordinates specified\n", "    geom_col()"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    count(yr) %>%\n", "    # \"aes()\" stands for \"aesthetic\". \n", "    # Anything within `aes()` refers to information from our data (stops_w_yr)\n", "    ggplot(aes(x = yr, y = n)) + \n", "    # geom_point adds points at the x and y coordinates specified\n", "    geom_point() + \n", "    # geom_line draws lines between x and y coordinates specified\n", "    geom_line()"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    count(yr) %>%\n", "    # \"aes()\" stands for \"aesthetic\". \n", "    # Anything within `aes()` refers to information from our data (stops_w_yr)\n", "    ggplot(aes(x = yr, y = n)) + \n", "    # geom_point adds points at the x and y coordinates specified\n", "    geom_point() + \n", "    # geom_line draws lines between x and y coordinates specified\n", "    geom_line() +\n", "    # we can use the function below to control the y axis\n", "    scale_y_continuous(limits = c(0,150000))"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# If we want to look date-by-date, we can just use `date` as our x-axis\n", "# And then we can call on the \"histogram\" function (which would be the\n", "# same as doing a `count(date)` and then a geom_col with x = date, y = n).\n", "# The benefit of geom_histogram() over the count and geom_col method, is that\n", "# with geom_histogram you can control the granularity of your bars.\n", "# Play around with `bins` to see!\n", "stops_w_yr %>%\n", "    ggplot(aes(x = date)) +\n", "    geom_histogram(bins = 500)"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# To focus in on the missing date range, we can use `scale_x_date()` to\n", "# add some breaks in our x-axis.\n", "stops_w_yr %>%\n", "    ggplot(aes(x = date)) +\n", "    geom_histogram(bins = 500) +\n", "    scale_x_date(date_breaks = \"1 year\") +\n", "    theme(axis.text.x = element_text(angle = 45, hjust = 1))"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# We can also look at the by-date, by-gender trends using \"fill\" \n", "# to distinguish between genders in our dataset\n", "# NOTE: bars/cols/histograms use \"fill\" to make color, \n", "#       points and lines use \"color\"\n", "stops_w_yr %>%\n", "    ggplot(aes(x = date, fill = gender)) +\n", "    geom_histogram(bins = 500) +\n", "    scale_x_date(date_breaks = \"1 year\") +\n", "    theme(axis.text.x = element_text(angle = 45, hjust = 1))"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Exercise 2: Plotting\n", "\n", "Create a point and line plot that shows by-year stop counts colored by race."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Nice! We'll get back to plotting in a bit. There are _endless_ tweaks and modifications and aesthetic optimizations you can fill your life with. We won't get into too many of those, but there are lots of resources online -- so once you get the basic structure or your plot, making it beautiful is well within reach!\n", "\n", "Ok. Back to our question about missing data. How would we figure this out without a plot? We basically want to apply the same command to each of the years, rather than filtering one at a time to each year. The key to doing this type of manipulation uses two new functions: `group_by` and `summarize`.\n", "\n", "**tidyverse functions: `group_by()` and `summarize()`**\n", "\n", "One thing that we often want to do with data is disaggregate it. That is, we\n", "might want to take the data and break it down into smaller subpopulations. Then,\n", "when we ask questions, we can ask about each piece---for instance, each\n", "demographic group, each year, or each police district---instead of asking about the population as a whole.\n", "\n", "The way to do this in `R` is with `group_by()` and `summarize()`. The standard way\n", "to use `group_by()` is to call `group_by(DATA, COL_NAME)`, where \n", "* `DATA` is our dataframe and \n", "* `COL_NAME` is the name of a column. \n", "What `group_by()` then does is\n", "take all the rows in the dataframe `DATA` and put them into different groups,\n", "one for each different value in the column `COL_NAME`. So, for instance, if we\n", "called `group_by(stops_w_yr, district)`, `R` would hand back to us the `stops_w_yr`\n", "dataframe with all of its columns broken into different groups, one for each\n", "police district. (Note: At this stage, the dataframe doesn't _look_ any different to the human eye, since the groupings are happening behind the scenes.)\n", "\n", "Try it below!"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    group_by(district)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["The second step is to do something with those groups. That's what `summarize()`\n", "does. The way `summarize()` works is to take a dataframe broken into groups by\n", "`group_by()` and calculate a statistic for each group. The basic syntax is\n", "`summarize(DATA, STAT = FUN(COL_NAME))`, where \n", "* `DATA` is some dataframe broken\n", "up by `group_by()`, \n", "* `STAT` is some statistic we want to calculate, \n", "* `FUN` is the\n", "function that calculates that statistic, and \n", "* `COL_NAME` is the name of the\n", "column (or columns) used to calculate the statistic.\n", "\n", "Let's put it all together with a few examples first."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    group_by(district) %>%\n", "    summarize(\n", "        # The function n() just gives us the number of rows in each gropu\n", "        n_stops = n(),\n", "        n_arrests = sum(arrested),\n", "        arrest_rate = n_arrests / n_stops\n", "    )"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    group_by(district) %>%\n", "    summarize(most_recent_stop = max(date))"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 3: Date ranges by year\n", "\n", "Using your new friends `group_by` and `summarize`, compute the min and max dates for each year. (Hint: Using `range()` alone will give you an error, because it returns two values, which we can't shove into one column. Try using `min()` and `max()` to make two separate columns, or you can try doing some wizardly string magic to make a single column out of the `range()` output!)"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Back to calculating disparities\n", "\n", "In that aside we discovered 2014 and 2016 only have partial years. Let's return to our 2015 dataset, `stops_2015` and calculate how many stops were made of drivers of each race group."]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 4: Stops by race group\n", "\n", "For this next exercise, let's compute the racial breakdown of traffic stops. To do this, we'll need two functions that we've already seen: `count()` and `mutate()`.\n", "\n", "1. Count how many stops per race group our `stops_2015` dataset has, saving your result to a new dataframe: `stops_by_race`. \n", "\n", "2. Describe in words what we'd need to do to find the proportion of stops that were of white drivers.\n", "\n", "3. To do the above computation for each race group, we can add additional column to `stops_by_race` using the `mutate()` function. Overwrite `stops_by_race`, adding a new column `p` with the proportion of stops that were made of drivers of each race group.\n", "\n", "4. Discuss: What do these proportions mean? Are drivers of certain race groups being stopped more than others? What might we be missing to really start interpreting these values?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# EXERCISE 2: YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Stop rates\n", "\n", "In order to do this baseline comparison, we need to understand the racial\n", "demographics in our SF population data. (Note: This is why we wanted just one full year: comparing the number of stops in a year to the population from that year.) The data as we've given it to you\n", "has raw population numbers from 2015. To make it useful, we'll need to compute the\n", "_proportion_ of SF residents in each demographic group. As before, we do this using the `mutate()` function.\n", "\n", "### You try\n", "\n", "* Take a look at `pop_2015`, then\n", "* mutate `pop_2015`, adding a column `p` that shows us what proportion of the population is white, black, Hispanic, Asian, and other."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Find the racial breakdown of SF's 2015 population\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Discuss\n", "\n", "What do the population proportions tell you about the stop proportions we computed before?\n", "\n", "\n", "### Adding rigor\n", "\n", "We can tell a lot just by eyeballing these two sets of proportions. But let's be a bit more\n", "rigorous about this. If we merge the two tables together, we can compute stop \n", "rates by race group (i.e., number of stops per person). "]}, {"metadata": {}, "cell_type": "markdown", "source": ["**R function: `inner_join()`**\n", "\n", "One way to put tables together is with the `inner_join()` function. We need to\n", "input three things into this function: \n", " 1. our main table\n", " 2. the second table we'd like to join with the first table, and\n", " 3. instructions on how to join them. \n", "\n", "In this case, the two tables we\n", "want to merge are \n", " 1. the table of stops counted according to `race`, and\n", " 2. the table of population by race: `pop_2015`. \n", " \n", "The instruction for combining the tables is \n", " 3. to merge rows that give information about the same race groups.\n", "\n", "To implement 3., we give `inner_join()` the argument `by =\n", "\"race\"`. This means that `inner_join()` will \n", " * look at the first table---\n", "i.e., the table stops counted by race---and go to the `race` column\n", "in each row.\n", " * Then, `inner_join()` will take what it finds there---in this case,\n", "`\"asian/pacific islander\"`, `\"black\"`, `\"hispanic\"`, `\"other/unknown\"`, and\n", "`\"white\"`---and look in the second table, i.e., `pop_2015`, for all the\n", "rows that contain the same information in `pop_2015`'s race column.\n", " * Finally,\n", "it will add the second row at the end of the first to create a new row with\n", "information from both. \n", "\n", "What we end up with is a dataframe with all of the\n", "columns from _both_ tables.\n", "\n", "The process is a little complicated, and we won't use it too much, so don't\n", "worry if the abstract description doesn't make sense. To get a better\n", "understanding of what's going on, exercise 5 will help guide you through merging the two tables described above,\n", "being sure to include the `by = \"race\"` argument.\n"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 5: computing stop rates by race group\n", "\n", "1. First, merge together `stops_by_race` and `pop_2015` by \"race\", using the `merge()` function. Name your result `stops_and_pop_by_race`.\n", "2. Add a column `stop_rate` to `stops_and_pop_by_race`, that is simply the number of stops divided by the number of people. (Hint: the `mutate()` function will be helpful!)\n", "3. Now we can divide the black (or Asian, or Hispanic, or \"other\") stop rate by the white stop rate to be able to make \n", "a quantitative statement about how much more often black drivers are stopped compared to white drivers, relative to their share of the city's population. Using `R` as a calculator, do this!\n", "4. Discuss your results."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# EXERCISE 3: YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["### Thought exercise: where stop rates fall short\n", "\n", "While these baseline stats give us a sense that there are racial disparities in\n", "policing practices in SF, they are not strong evidence of discrimination. The\n", "argument against using stop rates (often called \"benchmarking\" or the \"benchmark test\") is that we haven't identified the correct\n", "baseline to compare to. \n", "* Why isn't population the best thing to compare to (i.e., the best denominator of our stop rate)?\n", "* What would the ideal denominator of our stop rate be?\n", "* What other baselines (denominators) could we use? Are any of these ideal?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Your thoughts here (or just discuss)\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Searches\n", "\n", "Let's next consider how often drivers of different race groups were searched. Computing search rates is actually easier than stop rates because we don't need an external population benchmark.\n", "We can use the stopped population as our baseline, defining search rate to be the proportion of stopped people who were subsequently searched. "]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 6: Search rates\n", "\n", "1. Compute search rates by race group. (Hint: Think about what information you'd need to compute a search rate. The `n()` function might be helpful!)\n", "2. Discuss the search rate findings. Are some race groups searched more often than other race groups, relative to their share of stopped drivers?\n", "\n", "NOTE: Since we're not comparing to population numbers, we can return to using our full `stops_w_yr` dataset, with all years, because in this case it doesn't matter that we don't have full years for 2014 and 2016."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 7: Tricks with booleans\n", "\n", "Below is one possible solution to Exercise 6. The function `mean()` is defined over _numbers_, but `searched` is a column of booleans (TRUE/FALSE). Why does this solution work? Play around with treating booleans like numbers. What do you discover? (This behavior is called _coercion_.)"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["stops_w_yr %>%\n", "    group_by(race) %>%\n", "    summarize(\n", "        search_rate = mean(searched)\n", "    )"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Thought exercise: where search rates fall short\n", "* Do search rates have similar issues as we found with stop rates? Why or why not?\n", "* What might \"justifiably\" lead search rates to differ by race group?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Write your thoughts here (or just discuss)!\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Outcome test\n", "\n", "To circumvent the benchmarking problem, it's common to turn to the search \n", "decision, rather than the stop decision. This is because we have a notion of\n", "what a \"successful\" search is. The legal justification for performing a search\n", "is probable cause that the driver possesses contraband. So a successful search\n", "is one which uncovers contraband.\n", "\n", "We thus turn to rates of successful searches. That is, what proportion of\n", "searches, by race, were successful? This proportion is known as the contraband\n", "recovery rate, or the \"hit rate.\" If racial groups have different hit rates, it\n", "can imply that racial groups are being subjected to different standards."]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Thought Exercise: Hit rate interpretation\n", "\n", "As a caricatured example, suppose among white drivers who were searched, \n", "officers found contraband 99% of the time, while among black drivers who were\n", "searched, officers found contraband only 1% of the time. \n", "* Is this police department's search policy discriminatory? \n", "* Why or why not?\n", "* In general how can we use hit rates to understand whether a search policy is discriminatory?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Write your thoughts here (or just discuss)!\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["\n", "Next let's investigate a non-caricatured case: real hit rates by race group in SF."]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 8: Hit rates\n", "\n", "1. Filter to drivers who were searched, and then compute the hit rate (rate of contraband recovery) by race group. Remember your `group_by()` and `summarize()` functions!\n", "\n", "2. Discuss your findings. "]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["What if hit rates vary by police district? If the bar for stopping\n", "people, irrespective of race, is lower in certain police districts, and black\n", "individuals are more likely to live in neighborhoods in those districts, then\n", "the observed disparities may not reflect bias."]}, {"metadata": {}, "cell_type": "markdown", "source": ["Let's compute hit rates by race _and_ district. We can do this simply by adding multiple arguments to the `group_by()` function. Run the code below."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["hit_rates <- \n", "  stops_w_yr %>% \n", "  filter(searched) %>% \n", "  group_by(race, district) %>% \n", "  summarize(hit_rate = mean(contraband_found))\n", "\n", "hit_rates %>% nrow()"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["This is too many hit rates to compare in one table!"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 9: Visualization brainstorm\n", "\n", "Sketch out using pen and paper (or just describe to a partner) how you might try to use visualizations to help us synthesize the 50 hit rates above. Start with the question we're trying to answer (Are hit rates for minority drivers lower than hit rates for white drivers?) -- and then think about what type of plot might best help you answer that question. See if you can come up with at least 3 different sketches!"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## One way to visualize: scatterplots"]}, {"metadata": {}, "cell_type": "markdown", "source": ["One way to visualize the data is to make a scatterplot comparing white hit rates to each non-white race group. To do this, though, we need to reshape our data, so that each row allows us to compare white hit rate in a district, to each minority hit rate in that same district. \n", "\n", "The code below uses some tricky functions `spread` and `gather`. They're notoriously mind-bending, so the `tidyverse` team is actually developing new functions (`pivot_wider()` and `pivot_longer()`) to replace them soon. We'll walk you through this below, but don't get too hung up on it, since soon (like any day now) there will be more intuitive versions of these functions released."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Reshape table to show hit rates of minorities vs white drivers\n", "reshaped_hit_rates <-\n", "  hit_rates %>% \n", "  # the column names (key) will be race, the values will be from hit rate\n", "  spread(key = race, value = hit_rate, fill = 0) %>% \n", "  rename(white_hit_rate = white) %>% \n", "  # gather leaves us with two new columns: \n", "  # minority race (which contain the old colnames)\n", "  # and minority hit rate (which contains the values in the old columns)\n", "  gather(\n", "      key = minority_race, value = minority_hit_rate, \n", "      # columns to gather:\n", "      c(black, hispanic, `asian/pacific islander`, other)\n", "  ) %>%\n", "  arrange(district)\n", "\n", "head(hit_rates %>% arrange(district))\n", "head(reshaped_hit_rates)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Now we're ready to make a basic scatter plot! We'll walk you through it in the exercise below.\n", "\n", "## Exercise 10: Scatterplot of racial disparities\n", "\n", "1. Warm-up. Before we plot, let's do some tidyverse magic. To make our plot nice in step 2, we'll need the range of hit rates. Create a variable `max_hit_rate` that extracts the largest hit rate value in `reshaped_hit_rates`. There are many many different ways to do this, so don't be afraid to play around!\n", "2. Onward to plotting! First let's start simple. Filter `reshaped_hit_rates` to just `black` and `white` race groups (i.e., let's only consider rows where `minority_race` is \"black\"). Let's next create a scatterplot comparing black and white hit rates. Consider the following questions/hints:\n", "  * What do you want your x- and y-axes to be?\n", "  * Which `geom_X` would you use to creat scatterplot points?\n", "  * We want to compare apples to apples, so we want the x- and y-axis scales to cover the same range. To do this, we can use `scale_x_continuous()` and `scale_y_continuous()`. Both of these functions have an argument called `limits`. The basic usage is `scale_x_continuous(limits = c(A, B))`, where `A` is the lower limit of your range (we can just use 0), and `B` is the upper limit of your range (we can `max_hit_rate` from Q1 above). \n", "    Try adding and removing these two lines of code -- how does it change the plot? Why is it critical in this case?\n", "3. Now, to incorporate all minority race groups in our dataset, let's return to the unfiltered `reshaped_hit_rates`. Instead, let's create a panel for each race-pair we're comparing. We can do this simply by adding `facet_wrap(facets = vars(minority_race))` to the previous code. Try it! What do you see?"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE (EXERCISE 10, Q1)\n"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE (EXERCISE 10, Q2)\n"], "outputs": []}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE (EXERCISE 10, Q3)\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Below are some slight tweaks to make the plot a bit more readable. Let's go through these additions together to make sure they make sense. Below, we're going to:\n", "* Size the points by number of searches\n", "* Add a reference line in to demarcate \"fairness\"\n", "* Use percentages rather than proportions for the axes\n", "* Make the labels pretty"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# Get corresponding number of searches (to size points).\n", "# Again, for each district we want to know the number of white+black searches\n", "# and white+Hispanic searches. This requires the same spreading and gathering\n", "# as our previous data-munging.\n", "search_counts <-\n", "  stops_w_yr %>% \n", "  filter(searched) %>%  \n", "  count(district, race) %>% \n", "  spread(race, n, fill = 0) %>% \n", "  rename(num_white_searches = white) %>% \n", "  gather(\n", "      minority_race, num_minority_searches, \n", "      c(black, hispanic, `asian/pacific islander`, other)\n", "  ) %>% \n", "  mutate(num_searches = num_minority_searches + num_white_searches) %>% \n", "  select(district, minority_race, num_searches)\n", "\n", "# Now let's plot!\n", "reshaped_hit_rates %>% \n", "  left_join(\n", "    search_counts, \n", "    by = c(\"district\", \"minority_race\")\n", "  ) %>% \n", "  ggplot(aes(\n", "    x = white_hit_rate,\n", "    y = minority_hit_rate\n", "  )) +\n", "  geom_point(aes(size = num_searches), pch = 21) +\n", "  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\") +\n", "  scale_x_continuous(\"White hit rate\", \n", "    limits = c(0, max_hit_rate + 0.01),\n", "    labels = scales::percent_format(accuracy = 1),\n", "    # forces axis to start _right_ at zero, no gap\n", "    expand = c(0,0)\n", "  ) +\n", "  scale_y_continuous(\"Minority hit rate\", \n", "    limits = c(0, max_hit_rate + 0.01),\n", "    labels = scales::percent_format(accuracy = 1),\n", "    # forces axis to start _right_ at zero, no gap\n", "    expand = c(0,0)\n", "  ) +\n", "  coord_fixed() +\n", "  facet_wrap(vars(minority_race))"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Exercise 11: Plot interpretation\n", "\n", "Explain what you see above. What does each point represent? What does the dotted line represent? What do these plots tell us about discrimination in search practices?"]}, {"metadata": {}, "cell_type": "markdown", "source": ["## Modeling\n", "\n", "Plotting allowed us to synthesize fifty hit rates into an understanding of racial disparities in SF's search policy. Our plot provides us with evidence that these searches are discriminatory against black and Hispanic drivers. \n", "\n", "What if we want to _quantify_ this disparity? Our plot just gives us intuition. Similar to how we were able to compute the ratio between black hit rates and white hit rates for the aggregate hit rate data (citywide), we might want to know what those ratios would be in each district. Instead of separately computing the hit rate for each race/district, we can instead use modeling to put numbers on these disparities. We can use *regression*: computing how likely an officer was to find contraband given the drivers' race and district.\n", "\n", "We're not going to teach the statistics behind regression right now. If you already know about regression, we're here to teach you how to run a regression in `R`. If you've never heard of regression before, maybe this short soiree into modeling will inspire you to learn! "]}, {"metadata": {}, "cell_type": "markdown", "source": ["Our _outcome_ or _response_ variable, `contraband_found`, is a boolean (TRUE/FALSE, or 1/0) -- also known as a \"binomial\" variable. Recall that when we have an binomial outcome like this, we use logistic regression.\n", "\n", "Below, we create a dataframe with just the searches, and we convert all categorical variables to factors. A \"factor\" in `R` is has explicit levels -- it's telling the model not to derive a coefficient for each value within `race` and `district` (rather than treating them as continuous variables, with a single coefficient).\n", "\n", "For the model itself, we use `glm()`, which stands for \"generalized linear model\". We simply give `glm()` a formula: `response ~ covariate_1 + covariate_2 + ... + covariate_n`, the data, and then we specify the type of model we want to fit using the `family` argument. Logistic regression is \"binomial\" family."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["library(broom) #library for turning messy r output to tidy dataframes\n", "\n", "searched_df <- stops_w_yr %>% \n", "    filter(searched) %>%\n", "    mutate(\n", "        race = factor(race),\n", "        district = factor(district)\n", "    )\n", "\n", "mod <- glm(\n", "    contraband_found ~ race + district, \n", "    data = searched_df, \n", "    family = 'binomial'\n", ")\n", "\n", "tidy(mod)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Notice that there is no term for \"asian/pacific islander\" or \"district A\" in the above table.  This is because they were set as reference levels, which happens whenever you use a categorical variable in a regression.  We want to set white as the reference level for race so that we can read the coefficients for other races as comparisons to white hit rates. We can do this using the `relevel` function. "]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["searched_df <- searched_df %>%\n", "    mutate(race = relevel(race, ref = 'white'))\n", "\n", "mod <- glm(\n", "    contraband_found ~ race + district, \n", "    data = searched_df, \n", "    family = 'binomial'\n", ")\n", "tidy(mod)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["Now let's summarize our results by pulling out only the information we care about."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["tidy(mod) %>%\n", "    filter(str_detect(term, \"race\")) %>%\n", "    mutate(\n", "        race = str_remove_all(term, \"race\"),\n", "        conf_int_95 = str_c(\n", "            \"(\", round(estimate - 1.96*std.error, 3),\n", "            \", \", round(estimate + 1.96*std.error, 3), \")\"\n", "        ),\n", "        likelihood_recovery_v_white = exp(estimate)\n", "    ) %>%\n", "    select(race, estimate, conf_int_95, likelihood_recovery_v_white)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["A _negative_ coefficient estimate tells us that searches of that race group are _less_ likely to recovery contraband than searches of white drivers in the same district.\n", "\n", "In line with our plots, we see that searches of both black and Hispanic drivers recover significantly less contraband than searches of white drivers. By exponentiating the point estimates, we can acquire values than allow us to make quantitative statements: Searches of black and Hispanic drivers recover contraband only 35% as often as searches of white drivers."]}, {"metadata": {}, "cell_type": "markdown", "source": ["### Model prediction\n", "\n", "Often times you'll want to train a model in order to use it to make predictions. Now that we have our model, `mod`, let's say we wanted to predict the probability that a white person living in district E who was searched would be found to have contraband on them. Here's how we'd do that:"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["person <- tibble(\n", "    race = c('white'),\n", "    district = c('E')\n", ")\n", "predict(mod, person, type = 'response') %>% round(3)"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["**Statistical note:** We need `type = 'response'` so that R knows we want it to output probabilities.  Otherwise, it will output log odds, which is the scale that logistic regression uses.  "]}, {"metadata": {}, "cell_type": "markdown", "source": ["### Exercise 12: Many predictions\n", "\n", "Instead of just passing one person to `predict()`, we can pass in lots of different people! \n", "1. Create a dataframe (or \"tibble\") called `people`, with 10 rows and two columns. As with `person` our columns will be \"race\" and \"district. Let's make all 10 people white, and each of them in a different district (there are 10 districts in our dataset). Hint: the function `rep()` might be helpful!\n", "2. Now use `predict` to calculate how likely a searched white person is to be carrying contraband in each district in SF."]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE\n"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Open-ended exploration\n", "\n", "Now that you have a majority of the tools you need to perform data analysis, let's take some time to let you explore! \n", "\n", "### Exercise 13: Exploring SF traffic stops\n", "\n", "Come up with a question you have about the SF traffic stops dataset and see if you can use your new `R` skills to answer it!\n", "\n", "If you're having a lapse in creative questioning, here are a few to get you started:\n", "* What are arrest rates by race? By gender?\n", "* Check out the \"reason_for_stop\" column. Among stops made for \"Assistance to motorist\", what's the search rate for black men vs white men?\n", "* Are stops more likely to happen at certain times of day?\n"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": ["# YOUR CODE HERE"], "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": ["## Making maps\n", "\n", "For our final bit of `R`, let's get down some basics of map-making!"]}, {"metadata": {}, "cell_type": "markdown", "source": ["### Exercise 14:"]}, {"execution_count": 0, "metadata": {}, "cell_type": "code", "source": [], "outputs": []}], "metadata": {"language_info": {"name": "R", "version": "3.4.4", "mimetype": "text/x-r-source", "codemirror_mode": "r", "file_extension": ".r", "pygments_lexer": "r"}, "kernelspec": {"name": "ir", "display_name": "R", "language": "R"}}, "nbformat_minor": 2, "nbformat": 4}